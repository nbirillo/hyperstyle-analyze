{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdda50a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Validation of template errors search using manually found issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8634151",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb34ac94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a5e1ecc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set path to following csv files\n",
    "\n",
    "auto_filepath = '/Users/Anastasiia.Birillo/PycharmProjects/spbu/2021/spring/hyperstyle-analyze/data/templates/templates_filtered.csv'\n",
    "manual_filepath = '/Users/Anastasiia.Birillo/PycharmProjects/spbu/2021/spring/hyperstyle-analyze/data/templates/manual.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0adee0d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "\n",
    "ignore_issues = []\n",
    "ignore_frequency = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd916312",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Type'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/spbu/2021/spring/hyperstyle-analyze/main/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3080\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3079\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3080\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3081\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mpandas/_libs/index.pyx:70\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/index.pyx:101\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:4554\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:4562\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [18]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m df_manual \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(manual_filepath)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Filtering manual dataset\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m df_manual \u001B[38;5;241m=\u001B[39m df_manual[\u001B[43mdf_manual\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mType\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtemplate\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      7\u001B[0m df_manual[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIssue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_manual[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIssue.1\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      8\u001B[0m df_manual[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLine\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_manual[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTemplate\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mCode\u001B[39m\u001B[38;5;130;01m\\r\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mLine\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/spbu/2021/spring/hyperstyle-analyze/main/venv/lib/python3.8/site-packages/pandas/core/frame.py:3024\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3022\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3023\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3024\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3025\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3026\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/PycharmProjects/spbu/2021/spring/hyperstyle-analyze/main/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py:3082\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3080\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3081\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3082\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3084\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tolerance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   3085\u001B[0m     tolerance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_tolerance(tolerance, np\u001B[38;5;241m.\u001B[39masarray(key))\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Type'"
     ]
    }
   ],
   "source": [
    "df_auto = pd.read_csv(auto_filepath)\n",
    "df_manual = pd.read_csv(manual_filepath)\n",
    "\n",
    "# Filtering manual dataset\n",
    "\n",
    "df_manual = df_manual[df_manual['Type'] == 'template']\n",
    "df_manual['Issue'] = df_manual['Issue.1']\n",
    "df_manual['Line'] = df_manual['Template\\r\\nCode\\r\\nLine']\n",
    "df_manual = df_manual[['Step id', 'Issue', 'Line', '%']]\n",
    "df_manual.rename(columns={\n",
    "    'Step id': 'step_id', \n",
    "    'Issue': 'origin_class', \n",
    "    'Line': 'pos_in_template', \n",
    "    '%': 'frequency',\n",
    "}, inplace=True)\n",
    "\n",
    "# Filtering auto dataset\n",
    "\n",
    "df_auto = df_auto[df_auto['step_id'].isin(df_manual['step_id'].unique())]\n",
    "df_auto['pos_in_template'] = df_auto['pos_in_template'].map(lambda x: x + 1)\n",
    "\n",
    "# Dropping out invalid issues\n",
    "\n",
    "df_auto = df_auto[~df_auto['origin_class'].isin(ignore_issues)]\n",
    "df_manual = df_manual[~df_manual['origin_class'].isin(ignore_issues)]\n",
    "\n",
    "df_auto = df_auto[df_auto['frequency'] > ignore_frequency]\n",
    "df_manual = df_manual[df_manual['frequency'] > ignore_frequency]\n",
    "\n",
    "df_auto = df_auto[~df_auto['pos_in_template'].isna()]\n",
    "df_manual = df_manual[~df_manual['pos_in_template'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4a6a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def parse_pos_in_template(x: str):\n",
    "    \"\"\"\n",
    "    Interpret sequence entries like '57-59', '89,91', '-', etc.\n",
    "    Examples:\n",
    "    '57-59' -> [57, 58, 59]\n",
    "    '89,91' -> [89, 91]\n",
    "    '31'    -> [31]\n",
    "    '-'     -> []\n",
    "    \"\"\"\n",
    "    \n",
    "    if x == 'nan' or x == '-':\n",
    "        return []\n",
    "    positions = [s.strip() for s in x.split(',')]\n",
    "    res = []\n",
    "    for pos in positions:\n",
    "        s = pos.split('-')\n",
    "        if len(s) > 1:\n",
    "            res += list(range(int(s[0]), int(s[1]) + 1))\n",
    "        else:\n",
    "            res.append(int(s[0]))\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_unique_pairs(df: pd.DataFrame, first_col: str, second_col: str):\n",
    "    return df.loc[:, [first_col, second_col]].drop_duplicates().values\n",
    "\n",
    "\n",
    "def broadcast(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Construct new dataframe where issues with compound position in template are represented as multiple issues.\n",
    "    \n",
    "    step_id | origin_class | pos_in_template | frequency      step_id | origin_class | pos_in_template | frequency\n",
    "    ----------------------------------------------------      ----------------------------------------------------\n",
    "    3830    | MagicNumber  | 45-47           | 0.84       ->  3830    | MagicNumber  | 45              | 0.84     \n",
    "    ...     | ...          | ...             | ...            3830    | MagicNumber  | 46              | 0.84     \n",
    "                                                              3830    | MagicNumber  | 47              | 0.84     \n",
    "                                                              ...     | ...          | ...             | ...      \n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['pos_in_template'] = df['pos_in_template'].map(lambda x: parse_pos_in_template(str(x)))\n",
    "    df_broadcasted = pd.DataFrame()\n",
    "    for row in df.iterrows():\n",
    "        for p in row[1]['pos_in_template']:\n",
    "            new_row = pd.DataFrame({\n",
    "                'step_id': [row[1]['step_id']], \n",
    "                'origin_class': [row[1]['origin_class']], \n",
    "                'pos_in_template': [p], \n",
    "                'frequency': [row[1]['frequency']], \n",
    "            })\n",
    "            df_broadcasted = pd.concat([df_broadcasted, new_row], axis=0, ignore_index=True)\n",
    "    return df_broadcasted\n",
    "            \n",
    "\n",
    "def number(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Construct new dataframe where issues with same step id and class are merged and counted.\n",
    "    \n",
    "    step_id | origin_class | pos_in_template | frequency      step_id | origin_class | cnt \n",
    "    ----------------------------------------------------      ----------------------------\n",
    "    3830    | MagicNumber  | 45              | 0.84           3830    | MagicNumber  | 3  \n",
    "    3830    | MagicNumber  | 56              | 0.11       ->  ...     | ...          | ...\n",
    "    3830    | MagicNumber  | 72-74           | 0.36           \n",
    "    ...     | ...          | ...             | ...            \n",
    "    \"\"\"\n",
    "    df_numbered = pd.DataFrame()\n",
    "    for step_id, issue in get_unique_pairs(df, 'step_id', 'origin_class'):\n",
    "        cur_df = df[(df['step_id'] == step_id) & (df['origin_class'] == issue)]\n",
    "        df_numbered = pd.concat([df_numbered, pd.DataFrame({\n",
    "            'step_id': [step_id], \n",
    "            'origin_class': [issue],\n",
    "            'cnt': [len(cur_df)], \n",
    "        })], axis=0, ignore_index=True)\n",
    "    return df_numbered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7283c7",
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def print_stats(all_manual_cnt, all_auto_cnt, matched_cnt, manual_only_cnt, auto_only_cnt):\n",
    "    print(f'''\n",
    "    manual total cnt: {all_manual_cnt}\n",
    "    auto total cnt: {all_auto_cnt}\n",
    "    manual and auto found: {matched_cnt}\n",
    "    manual only found: {manual_only_cnt}\n",
    "    auto only found: {auto_only_cnt}\n",
    "    (manual & auto) / (all manual): {matched_cnt / all_manual_cnt}\n",
    "    (auto only found) / (all auto): {auto_only_cnt / all_auto_cnt}\n",
    "    ''')\n",
    "\n",
    "    \n",
    "# Various validation functions\n",
    "    \n",
    "def match(df_auto, df_manual):\n",
    "    df_manual = broadcast(df_manual.copy())\n",
    "    \n",
    "    matched_cnt, auto_only_cnt, manual_only_cnt = 0, 0, 0\n",
    "    all_auto_cnt, all_manual_cnt = len(df_auto), len(df_manual)\n",
    "    df_not_matched = pd.DataFrame()\n",
    "    \n",
    "    for step_id in df_manual['step_id'].unique():\n",
    "        df_manual_step = df_manual[df_manual['step_id'] == step_id]\n",
    "        df_auto_step = df_auto[df_auto['step_id'] == step_id]\n",
    "        cur_cnt = 0\n",
    "        \n",
    "        for pos, issue in get_unique_pairs(df_manual_step, 'pos_in_template', 'origin_class'):\n",
    "            df_cur_auto = df_auto_step[(df_auto_step['pos_in_template'] == pos) & (df_auto_step['origin_class'] == issue)]\n",
    "            if len(df_cur_auto) > 0:\n",
    "                cur_cnt += 1\n",
    "            else:\n",
    "                manual_only_cnt += 1\n",
    "                df_not_matched = pd.concat([df_not_matched, pd.DataFrame({\n",
    "                    'step_id': [step_id], \n",
    "                    'origin_class': [issue], \n",
    "                    'pos_in_template': [pos]\n",
    "                })], axis=0, ignore_index=True)\n",
    "                \n",
    "        auto_only_cnt += len(df_auto_step) - cur_cnt\n",
    "        matched_cnt += cur_cnt\n",
    "        \n",
    "    print_stats(all_manual_cnt, all_auto_cnt, matched_cnt, manual_only_cnt, auto_only_cnt)\n",
    "    \n",
    "    return df_not_matched\n",
    "\n",
    "\n",
    "def match_numbered(df_auto: pd.DataFrame, df_manual: pd.DataFrame, mode: str = 'diff'):\n",
    "    modes = ['eq', 'diff']\n",
    "    if mode not in modes:\n",
    "        raise ValueError(f\"Unexpected mode: {mode}. Please select one of the following: {','.join([x for x in modes])}.\")\n",
    "    \n",
    "    df_auto = number(df_auto.copy())\n",
    "    df_manual = number(df_manual.copy())\n",
    "    \n",
    "    matched_cnt, auto_only_cnt, manual_only_cnt = 0, 0, 0\n",
    "    if mode == 'eq':\n",
    "        all_auto_cnt, all_manual_cnt = len(df_auto), len(df_manual)\n",
    "    elif mode == 'diff':\n",
    "        all_auto_cnt, all_manual_cnt = df_auto['cnt'].sum(), df_manual['cnt'].sum()\n",
    "    df_not_matched = pd.DataFrame()\n",
    "    \n",
    "    for step_id in df_auto['step_id'].unique():\n",
    "        df_manual_step = df_manual[df_manual['step_id'] == step_id]\n",
    "        df_auto_step = df_auto[df_auto['step_id'] == step_id]\n",
    "        cur_cnt = 0\n",
    "        \n",
    "        for issue, cnt in get_unique_pairs(df_manual_step, 'origin_class', 'cnt'):\n",
    "            if mode == 'eq':\n",
    "                df_cur_auto = df_auto_step[(df_auto_step['origin_class'] == issue) & (df_auto_step['cnt'] == cnt)]\n",
    "                if len(df_cur_auto) > 0:\n",
    "                    cur_cnt += 1\n",
    "                else:\n",
    "                    manual_only_cnt += 1\n",
    "                    df_not_matched = pd.concat([df_not_matched, pd.DataFrame({\n",
    "                        'step_id': [step_id], \n",
    "                        'origin_class': [issue], \n",
    "                        'cnt': [cnt]\n",
    "                    })], axis=0, ignore_index=True)\n",
    "            elif mode == 'diff':\n",
    "                df_cur_auto = df_auto_step[df_auto_step['origin_class'] == issue]\n",
    "                if len(df_cur_auto) > 0:\n",
    "                    auto_cnt = df_cur_auto.iloc[0,2]\n",
    "                    cur_cnt += min(cnt, auto_cnt)\n",
    "                    if auto_cnt > cnt:\n",
    "                        auto_only_cnt += auto_cnt - cnt\n",
    "                    elif auto_cnt < cnt:\n",
    "                        manual_only_cnt += cnt - auto_cnt\n",
    "                        df_not_matched = pd.concat([df_not_matched, pd.DataFrame({\n",
    "                            'step_id': [step_id], \n",
    "                            'origin_class': [issue], \n",
    "                            'cnt': [cnt - auto_cnt]\n",
    "                        })], axis=0, ignore_index=True)\n",
    "                else:\n",
    "                    manual_only_cnt += cnt\n",
    "                    \n",
    "        if mode == 'eq':\n",
    "            auto_only_cnt += len(df_auto_step) - cur_cnt\n",
    "            matched_cnt += cur_cnt\n",
    "        elif mode == 'diff':\n",
    "            for issue in df_auto_step[~df_auto_step['origin_class'].isin(df_manual_step['origin_class'].unique())]['origin_class'].unique():\n",
    "                df_cur_auto = df_auto_step[df_auto_step['origin_class'] == issue]\n",
    "                if len(df_cur_auto) > 0:\n",
    "                    auto_only_cnt += df_cur_auto.iloc[0,2]\n",
    "            matched_cnt += cur_cnt\n",
    "                    \n",
    "    print_stats(all_manual_cnt, all_auto_cnt, matched_cnt, manual_only_cnt, auto_only_cnt)\n",
    "    \n",
    "    return df_not_matched\n",
    "\n",
    "\n",
    "def match_sets(df_auto, df_manual):\n",
    "    df_auto = number(df_auto.copy())\n",
    "    df_manual = number(df_manual.copy())\n",
    "    \n",
    "    matched_cnt, auto_only_cnt, manual_only_cnt = 0, 0, 0\n",
    "    all_auto_cnt, all_manual_cnt = len(df_auto), len(df_manual)\n",
    "    df_not_matched = pd.DataFrame()\n",
    "\n",
    "    for step_id in df_manual['step_id'].unique():\n",
    "        df_manual_step = df_manual[df_manual['step_id'] == step_id]\n",
    "        df_auto_step = df_auto[df_auto['step_id'] == step_id]\n",
    "        cur_cnt = 0\n",
    "\n",
    "        for issue in df_manual_step['origin_class'].unique():\n",
    "            df_cur_auto = df_auto_step[df_auto_step['origin_class'] == issue]\n",
    "            if len(df_cur_auto) > 0:\n",
    "                matched_cnt += 1\n",
    "            else:\n",
    "                manual_only_cnt += 1\n",
    "                df_not_matched = pd.concat([df_not_matched, pd.DataFrame({\n",
    "                    'step_id': [step_id], \n",
    "                    'origin_class': [issue]\n",
    "                })], axis=0, ignore_index=True)\n",
    "\n",
    "        for issue in df_auto_step[~df_auto_step['origin_class'].isin(df_manual_step['origin_class'].unique())]['origin_class'].unique():\n",
    "            auto_only_cnt += 1\n",
    "            \n",
    "    print_stats(all_manual_cnt, all_auto_cnt, matched_cnt, manual_only_cnt, auto_only_cnt)\n",
    "    \n",
    "    return df_not_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e3594",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## General statistics on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500962ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "steps_n = len(df_manual['step_id'].unique())\n",
    "\n",
    "print(f\"Number of steps: {steps_n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f16d4b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'step_id'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m16\u001B[39m, \u001B[38;5;241m7\u001B[39m))\n\u001B[1;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mhist([df_auto\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep_id\u001B[39m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mint\u001B[39m(x))), \n\u001B[0;32m----> 3\u001B[0m     \u001B[43mdf_manual\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mby\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstep_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mint\u001B[39m(x)))], \n\u001B[1;32m      4\u001B[0m          bins\u001B[38;5;241m=\u001B[39msteps_n, label\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmanual\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      5\u001B[0m plt\u001B[38;5;241m.\u001B[39mxticks(rotation\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m45\u001B[39m, ha\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mright\u001B[39m\u001B[38;5;124m\"\u001B[39m, rotation_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124manchor\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mlegend()\n",
      "File \u001B[0;32m~/PycharmProjects/spbu/2021/spring/hyperstyle-analyze/main/venv/lib/python3.8/site-packages/pandas/core/frame.py:5455\u001B[0m, in \u001B[0;36mDataFrame.sort_values\u001B[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001B[0m\n\u001B[1;32m   5452\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   5454\u001B[0m     by \u001B[38;5;241m=\u001B[39m by[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m-> 5455\u001B[0m     k \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_label_or_level_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mby\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5457\u001B[0m     \u001B[38;5;66;03m# need to rewrap column in Series to apply key function\u001B[39;00m\n\u001B[1;32m   5458\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/spbu/2021/spring/hyperstyle-analyze/main/venv/lib/python3.8/site-packages/pandas/core/generic.py:1684\u001B[0m, in \u001B[0;36mNDFrame._get_label_or_level_values\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1682\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes[axis]\u001B[38;5;241m.\u001B[39mget_level_values(key)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m   1683\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1684\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[1;32m   1686\u001B[0m \u001B[38;5;66;03m# Check for duplicates\u001B[39;00m\n\u001B[1;32m   1687\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m values\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[0;31mKeyError\u001B[0m: 'step_id'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1152x504 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 7))\n",
    "plt.hist([df_auto.sort_values(by='step_id')['step_id'].map(lambda x: str(int(x))), \n",
    "    df_manual.sort_values(by='step_id')['step_id'].map(lambda x: str(int(x)))], \n",
    "         bins=steps_n, label=['auto', 'manual'])\n",
    "plt.xticks(rotation=45, ha=\"right\", rotation_mode='anchor')\n",
    "plt.legend()\n",
    "plt.title('Issues distribution by step id')\n",
    "plt.xlabel('step id')\n",
    "plt.ylabel('number of issues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76b4cff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d8f25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Matching by step, issue and position in template with broadcasting manually found issues:')\n",
    "df_not_matched = match(df_auto, df_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f7158",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Matching by step, issue class and number of such issues, numberes must be exactly equal to match:')\n",
    "df_not_matched = match_numbered(df_auto, df_manual, mode='eq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7446eccc",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Matching by step, issue class and number of such issues, considering difference between numbers:')\n",
    "df_not_matched = match_numbered(df_auto, df_manual, mode='diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1989adc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Matching by step and issue class only:')\n",
    "df_not_matched = match_sets(df_auto, df_manual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}